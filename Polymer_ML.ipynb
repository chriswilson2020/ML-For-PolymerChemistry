{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764d57ec-5f2c-4cab-b20b-7b6aebbf9abd",
   "metadata": {},
   "source": [
    "# Polymer Properties Machine Learning\n",
    "Data and methodology taken from: Estimation and Prediction of the Polymers’ Physical Characteristics Using the Machine Learning Models Polymers 2024, 16(1), 115; https://doi.org/10.3390/polym16010115.\n",
    "\n",
    "Github repository: https://github.com/catauggie/polymersML/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db837a3e-f796-47ab-b79d-9880c2ab22fa",
   "metadata": {},
   "source": [
    "The goal of this notebook is to begin the machine learning phase which follows on from importing the polymer properties and analysisng the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348aade1-307e-48bf-9771-974881e0829e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>polymer_name</th>\n",
       "      <th>Number of features</th>\n",
       "      <th>Features names</th>\n",
       "      <th>Flexural creep strain_value_median</th>\n",
       "      <th>Dielectric loss tangent_value_median</th>\n",
       "      <th>Tensile creep rupture time_value_median</th>\n",
       "      <th>Dynamic mechanical properties loss modulus_value_median</th>\n",
       "      <th>Pvt relation temperature_value_median</th>\n",
       "      <th>Vicat softening temperature_value_median</th>\n",
       "      <th>...</th>\n",
       "      <th>Thermal decomposition temperature_value_variance</th>\n",
       "      <th>Dynamic mechanical properties loss tangent_value_variance</th>\n",
       "      <th>Hansen parameter delta-d: dispersion component_value_variance</th>\n",
       "      <th>Dynamic viscosity loss tangent_value_variance</th>\n",
       "      <th>Volume resistivity_value_variance</th>\n",
       "      <th>Water absorption_value_variance</th>\n",
       "      <th>Heat of fusion_value_variance</th>\n",
       "      <th>Dynamic flexural properties storage modulus_value_variance</th>\n",
       "      <th>Dynamic shear properties storage modulus_value_variance</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>polyethene</td>\n",
       "      <td>93</td>\n",
       "      <td>['Density', 'Specific volume', 'Refractive ind...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00045</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.150</td>\n",
       "      <td>180.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7598.312090</td>\n",
       "      <td>0.008877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3354844969133619982821830547268557602816</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>1.138410</td>\n",
       "      <td>3.445363e-01</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>poly(prop-1-ene)</td>\n",
       "      <td>86</td>\n",
       "      <td>['Density', 'Specific volume', 'Refractive ind...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>95.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6815.698995</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>NaN</td>\n",
       "      <td>588.0</td>\n",
       "      <td>1620381465120619970405709793344880640</td>\n",
       "      <td>0.610991</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>100.427099</td>\n",
       "      <td>1.030412e+00</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>poly(but-1-ene)</td>\n",
       "      <td>41</td>\n",
       "      <td>['Density', 'Specific volume', 'Refractive ind...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140</td>\n",
       "      <td>240.9</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.159326e-09</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      polymer_name  Number of features  \\\n",
       "0           0        polyethene                  93   \n",
       "1           1  poly(prop-1-ene)                  86   \n",
       "2           2   poly(but-1-ene)                  41   \n",
       "\n",
       "                                      Features names  \\\n",
       "0  ['Density', 'Specific volume', 'Refractive ind...   \n",
       "1  ['Density', 'Specific volume', 'Refractive ind...   \n",
       "2  ['Density', 'Specific volume', 'Refractive ind...   \n",
       "\n",
       "   Flexural creep strain_value_median  Dielectric loss tangent_value_median  \\\n",
       "0                                 NaN                               0.00045   \n",
       "1                                 NaN                               0.00100   \n",
       "2                                 NaN                                   NaN   \n",
       "\n",
       "   Tensile creep rupture time_value_median  \\\n",
       "0                                     10.0   \n",
       "1                                  20000.0   \n",
       "2                                      NaN   \n",
       "\n",
       "   Dynamic mechanical properties loss modulus_value_median  \\\n",
       "0                                              0.150         \n",
       "1                                              0.086         \n",
       "2                                              0.140         \n",
       "\n",
       "   Pvt relation temperature_value_median  \\\n",
       "0                                  180.0   \n",
       "1                                   95.0   \n",
       "2                                  240.9   \n",
       "\n",
       "   Vicat softening temperature_value_median  ...  \\\n",
       "0                                     123.0  ...   \n",
       "1                                     138.0  ...   \n",
       "2                                      99.0  ...   \n",
       "\n",
       "   Thermal decomposition temperature_value_variance  \\\n",
       "0                                       7598.312090   \n",
       "1                                       6815.698995   \n",
       "2                                               NaN   \n",
       "\n",
       "   Dynamic mechanical properties loss tangent_value_variance  \\\n",
       "0                                           0.008877           \n",
       "1                                           0.022569           \n",
       "2                                                NaN           \n",
       "\n",
       "   Hansen parameter delta-d: dispersion component_value_variance  \\\n",
       "0                                                0.0               \n",
       "1                                                NaN               \n",
       "2                                                NaN               \n",
       "\n",
       "   Dynamic viscosity loss tangent_value_variance  \\\n",
       "0                                            NaN   \n",
       "1                                          588.0   \n",
       "2                                            NaN   \n",
       "\n",
       "          Volume resistivity_value_variance  Water absorption_value_variance  \\\n",
       "0  3354844969133619982821830547268557602816                         0.001996   \n",
       "1     1620381465120619970405709793344880640                         0.610991   \n",
       "2                                                                        NaN   \n",
       "\n",
       "   Heat of fusion_value_variance  \\\n",
       "0                       0.000221   \n",
       "1                       0.000071   \n",
       "2                       0.000152   \n",
       "\n",
       "   Dynamic flexural properties storage modulus_value_variance  \\\n",
       "0                                           1.138410            \n",
       "1                                         100.427099            \n",
       "2                                                NaN            \n",
       "\n",
       "   Dynamic shear properties storage modulus_value_variance  \\\n",
       "0                                       3.445363e-01         \n",
       "1                                       1.030412e+00         \n",
       "2                                       1.159326e-09         \n",
       "\n",
       "                                              vector  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[3 rows x 202 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go ahead and import the data into a dataframe and then make sure its imported properly by listing the first few lines\n",
    "import pandas as pd\n",
    "poly_data = pd.read_excel('resulting_dataset_master.xlsx')\n",
    "poly_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe587b7-8d69-436a-886e-493e5f8a077b",
   "metadata": {},
   "source": [
    "Now we need to do some further manipulation so in the code block below we develop a process for handling and manipulating the columns in the pandas DataFrame `df`imported from `poly_data` that contains string representations of lists, with the goal of standardizing the length of these lists by padding them with zeros. we do this because **converting a molecular fingerprint** into separate columns before training a neural network is a crucial step in preparing the data for machine learning models, especially neural networks.\n",
    "\n",
    "This transformation serves several important purposes:\n",
    "\n",
    "1. Fxed-length Input: Neural networks require a fixed-size input for all samples. Molecular fingerprints, however, can vary in size depending on the molecule they represent. Padding these fingerprints to a uniform length and then splitting them into separate columns ensures that each input fed into the neural network has the same dimensions, which is a fundamental requirement for training.\n",
    "2. Feature Representation: Each bit in a molecular fingerprint represents the presence or absence (1 or 0) of a particular molecular substructure or feature. By converting a fingerprint into separate columns, each feature becomes an individual input neuron in the neural network. This allows the neural network to learn which particular features (i.e., substructures within the molecules) are important for predicting the target variable, whether it be the molecule's activity, toxicity, solubility, or any other property of interest.\n",
    "3. Sparse Data Handling: Molecular fingerprints are typically sparse, meaning they contain many more zeros than ones. Handling them in a format where each bit is a separate feature allows neural networks (and other machine learning models) to more efficiently process and learn from the sparse data. Some neural network architectures or layers are specifically designed to handle sparse data efficiently.\n",
    "4. Scalability and Parallel Processing: By structuring the data into a matrix where each column is a feature, it aligns well with the way neural networks operate, allowing for efficient batch processing and parallel computation. Neural networks, especially those implemented in frameworks like TensorFlow or PyTorch, are optimized for operations on matrices and can leverage GPU acceleration. This matrix format enables faster training and prediction times by allowing the model to process multiple samples in parallel.\n",
    "5. Interpretability and Feature Engineering: Although neural networks are often considered \"black boxes,\" having features as separate columns can slightly improve the interpretability of the input data. It allows researchers to potentially identify which specific substructures contribute most to the model's predictions. Additionally, this format makes it easier to apply feature engineering techniques, such as feature selection or the creation of new features through transformations of existing ones.\n",
    "\n",
    "*In summary, converting molecular fingerprints into separate columns before feeding them into a neural network is a standard preprocessing step that aligns with the technical requirements of neural networks and maximizes their ability to learn from the data. This step ensures that the input data is structured in a way that is computationally efficient and conducive to learning meaningful patterns related to the molecules' properties.*\n",
    "\n",
    "Let's break down the code step by step:<br>\n",
    "**1. Import Statements:**\n",
    "* `import pandas as pd`: Imports the pandas library, a powerful tool for data manipulation and analysis, and gives it the alias `pd`.\n",
    "`import ast`: Imports the ast module, which allows Python applications to process trees of the Python abstract syntax grammar. Here, it's used for the `literal_eval` function.\n",
    "`import numpy as np`: Imports the numpy library, a fundamental package for scientific computing in Python, and gives it the alias `np`.\n",
    "\n",
    "2. DataFrame Assignment:\n",
    "* We create a copy of the data in `df = poly_data``\n",
    "\n",
    "3. Conversion of String Representations of Lists to Actual Lists:\n",
    "`df['vector'] = df['vector'].apply(ast.literal_eval)`: This line converts the string representations of lists in the `vector` column of `df` into actual list objects. The `ast.literal_eval` function safely evaluates a string containing a Python literal or container display.\n",
    "\n",
    "4. Finding the Maximum Length of Lists:\n",
    "`max_length = max(len(lst) for lst in df['vector'])`: This line calculates the maximum length among all the lists contained in the `vector` column of df.\n",
    "\n",
    "5. Padding the Lists:\n",
    "The code creates a new list of lists called `padded_lists` where each inner list (originally from the `vector` column) is extended with zeros to match the length of the longest list. This is achieved with a list comprehension that adds `[0] * (max_length - len(lst))` to each list, ensuring they all have the same length.\n",
    "\n",
    "6. Creating a New DataFrame with Padded Lists:\n",
    "`new_df = pd.DataFrame(padded_lists, columns=[f'col_{i}' for i in range(max_length)])`: This line creates a new DataFrame `new_df` from padded_lists. Each list becomes a row in `new_df`, with each element of the list in its own column. The columns are named sequentially (`col_0, col_1, ..., col_n`) based on the maximum length of the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceea1784-be34-44b7-abe7-d164c34d8c06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_1014</th>\n",
       "      <th>col_1015</th>\n",
       "      <th>col_1016</th>\n",
       "      <th>col_1017</th>\n",
       "      <th>col_1018</th>\n",
       "      <th>col_1019</th>\n",
       "      <th>col_1020</th>\n",
       "      <th>col_1021</th>\n",
       "      <th>col_1022</th>\n",
       "      <th>col_1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18308</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18309</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18310</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18311</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18312 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9  \\\n",
       "0          0      0      0      0      0      0      0      0      0      0   \n",
       "1          0      1      0      0      0      0      0      0      0      0   \n",
       "2          1      1      0      0      0      0      0      0      0      0   \n",
       "3          0      1      0      0      0      0      0      0      0      0   \n",
       "4          0      1      0      0      0      0      0      0      0      0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "18307      0      0      0      0      0      0      0      0      0      0   \n",
       "18308      0      0      0      0      1      0      0      0      0      0   \n",
       "18309      0      0      0      0      0      0      0      0      0      0   \n",
       "18310      0      0      0      0      0      0      0      1      0      0   \n",
       "18311      0      0      0      0      0      0      0      1      0      0   \n",
       "\n",
       "       ...  col_1014  col_1015  col_1016  col_1017  col_1018  col_1019  \\\n",
       "0      ...         0         0         0         0         0         0   \n",
       "1      ...         0         0         0         0         0         0   \n",
       "2      ...         0         0         0         0         0         0   \n",
       "3      ...         0         0         0         0         0         0   \n",
       "4      ...         0         0         0         0         0         0   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "18307  ...         0         0         0         0         0         0   \n",
       "18308  ...         0         0         0         0         0         0   \n",
       "18309  ...         0         0         0         0         0         0   \n",
       "18310  ...         0         0         0         0         0         0   \n",
       "18311  ...         0         0         0         1         0         0   \n",
       "\n",
       "       col_1020  col_1021  col_1022  col_1023  \n",
       "0             0         0         0         0  \n",
       "1             0         0         0         0  \n",
       "2             0         0         0         0  \n",
       "3             0         0         0         0  \n",
       "4             0         0         0         0  \n",
       "...         ...       ...       ...       ...  \n",
       "18307         0         0         0         0  \n",
       "18308         0         0         0         0  \n",
       "18309         0         0         0         0  \n",
       "18310         0         0         0         0  \n",
       "18311         0         0         0         0  \n",
       "\n",
       "[18312 rows x 1024 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast  # Module for literal_eval function\n",
    "import numpy as np\n",
    "\n",
    "df = poly_data\n",
    "\n",
    "# Convert the string representations of lists to actual lists using ast.literal_eval\n",
    "df['vector'] = df['vector'].apply(ast.literal_eval)\n",
    "\n",
    "# Find the maximum length of lists in the 'vector' column\n",
    "max_length = max(len(lst) for lst in df['vector'])\n",
    "\n",
    "# Pad the lists with zeros to make them all the same length\n",
    "padded_lists = [lst + [0] * (max_length - len(lst)) for lst in df['vector']]\n",
    "\n",
    "# Create a new DataFrame with the padded lists\n",
    "new_df = pd.DataFrame(padded_lists, columns=[f'col_{i}' for i in range(max_length)])\n",
    "\n",
    "# Display the new DataFrame\n",
    "new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c22e4aa-8804-44bc-a77f-8b1dc2f04941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export the new dataframes to csv and excel files for archival and later use\n",
    "new_df.to_csv('cols.csv')\n",
    "new_df.to_excel('cols.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb196a7f-b6d4-4aad-b8fc-befddab7842b",
   "metadata": {},
   "source": [
    "If we output the first two lines of the data frame `new_df` we can see this now has 1024 columns of binary data representing the molecular fingerprints (0s and 1s).  There is no other data in this dataframe so in order to make some further steps we need to add in the data of interest for our machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07e4743d-982f-4307-bad0-9d7f70b2cac9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_1014</th>\n",
       "      <th>col_1015</th>\n",
       "      <th>col_1016</th>\n",
       "      <th>col_1017</th>\n",
       "      <th>col_1018</th>\n",
       "      <th>col_1019</th>\n",
       "      <th>col_1020</th>\n",
       "      <th>col_1021</th>\n",
       "      <th>col_1022</th>\n",
       "      <th>col_1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9  ...  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "1      0      1      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "   col_1014  col_1015  col_1016  col_1017  col_1018  col_1019  col_1020  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "\n",
       "   col_1021  col_1022  col_1023  \n",
       "0         0         0         0  \n",
       "1         0         0         0  \n",
       "\n",
       "[2 rows x 1024 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a171260d-e6d7-480a-9e4e-e6e7b0881314",
   "metadata": {},
   "source": [
    "We want to start with the Tg or glass transition temperature of the homopolymers and specificially the median value that we entered into the dataset in the import step.  Here is how we do that:\n",
    "\n",
    "1. Assign a Column from One DataFrame to Another:\n",
    "`new_df['Glass transition temperature_value_median'] = poly_data['Glass transition temperature_value_median']`\n",
    "This line copies the column named 'Glass transition temperature_value_median' from the poly_data DataFrame into the new_df DataFrame. If the column doesn't exist in new_df, it will be created. If it does exist, its current values will be replaced with the values from poly_data. This operation aligns data based on the index of the DataFrame, meaning each row's value in new_df will correspond to the row with the same index in poly_data.\n",
    "\n",
    "2. Drop a Column from a DataFrame:\n",
    "`new_df.drop(['Unnamed: 0'], axis=1, inplace=True, errors='ignore')`\n",
    "This line attempts to remove the column named 'Unnamed: 0' from new_df. Here are the specifics of the parameters used:\n",
    "axis=1 indicates that the operation should be performed on columns (as opposed to rows, which would be axis=0).\n",
    "inplace=True means that the DataFrame (new_df) will be modified in place. Without this, the operation would return a new DataFrame, leaving the original unchanged.\n",
    "errors='ignore' instructs pandas to do nothing if the column 'Unnamed: 0' does not exist in new_df. If this parameter were not included and the column didn't exist, the operation would raise an error.\n",
    "\n",
    "*Note: this is a carry over from the original publication and I believe a carry over from a different dataset.  There is no Unamed: 0 column in this dataset.  It doesn't have any functional use now and was throwing an error. The addition of errors='ignore' makes it a pretty begnin piece of code for now. I will remove it in future versions.*\n",
    "\n",
    "3. Filter rows with NaN:\n",
    "`new_df = new_df[new_df['Glass transition temperature_value_median'].isna() == False]`\n",
    "This line filters `new_df` to only include rows where the `Glass transition temperature_value_median` column does not contain NaN values. It achieves this by checking each row for a False return value from .isna(), indicating that the value is not NaN. The result is a possibly reduced DataFrame where all rows have a non-NaN value in the `Glass transition temperature_value_median` column. \n",
    "\n",
    "4. Display the First Few Rows of the DataFrame:\n",
    "`new_df.head(2)`\n",
    "This line displays the first two rows of new_df. The head() function is commonly used for quickly inspecting the first few rows of a DataFrame. By passing the argument 2, it specifies that only the first two rows should be shown. If you scroll all the way to the right you will see that the Tg values are now appended as a new column at the end. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "077f0043-1e47-455c-854a-786bba22fa86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_1015</th>\n",
       "      <th>col_1016</th>\n",
       "      <th>col_1017</th>\n",
       "      <th>col_1018</th>\n",
       "      <th>col_1019</th>\n",
       "      <th>col_1020</th>\n",
       "      <th>col_1021</th>\n",
       "      <th>col_1022</th>\n",
       "      <th>col_1023</th>\n",
       "      <th>Glass transition temperature_value_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9  ...  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "1      0      1      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "   col_1015  col_1016  col_1017  col_1018  col_1019  col_1020  col_1021  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "\n",
       "   col_1022  col_1023  Glass transition temperature_value_median  \n",
       "0         0         0                                     -60.00  \n",
       "1         0         0                                      -0.39  \n",
       "\n",
       "[2 rows x 1025 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['Glass transition temperature_value_median'] = poly_data['Glass transition temperature_value_median']\n",
    "new_df.drop(['Unnamed: 0'], axis=1, inplace=True, errors='ignore')\n",
    "new_df = new_df[new_df['Glass transition temperature_value_median'].isna() == False]\n",
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d25e7-6d57-4c5d-a74a-868d4ef0cfce",
   "metadata": {},
   "source": [
    "We do the same thing again for the variances importing a fresh version of the molecular fingerprints that we saved earlier.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae5dac8a-ae9e-4b67-a97a-1e1a390e4c77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_1015</th>\n",
       "      <th>col_1016</th>\n",
       "      <th>col_1017</th>\n",
       "      <th>col_1018</th>\n",
       "      <th>col_1019</th>\n",
       "      <th>col_1020</th>\n",
       "      <th>col_1021</th>\n",
       "      <th>col_1022</th>\n",
       "      <th>col_1023</th>\n",
       "      <th>Glass transition temperature_value_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2659.128411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>318.585297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9  ...  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "1      0      1      0      0      0      0      0      0      0      0  ...   \n",
       "\n",
       "   col_1015  col_1016  col_1017  col_1018  col_1019  col_1020  col_1021  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "\n",
       "   col_1022  col_1023  Glass transition temperature_value_variance  \n",
       "0         0         0                                  2659.128411  \n",
       "1         0         0                                   318.585297  \n",
       "\n",
       "[2 rows x 1025 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_new_df = pd.read_csv('cols.csv')\n",
    "var_new_df['Glass transition temperature_value_variance'] = poly_data['Glass transition temperature_value_variance']\n",
    "var_new_df.drop(['Unnamed: 0'], axis=1, inplace=True, errors='ignore')\n",
    "var_new_df = var_new_df[var_new_df['Glass transition temperature_value_variance'].isna() == False]\n",
    "var_new_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a027315a-4923-4cfa-b901-79058f9614c6",
   "metadata": {},
   "source": [
    "### First steps into machine learning\n",
    "Up to this point we have spent a lot of time in preparing the data pain stakingly making it fit to a particular format.  From hereon we will start to delve into machine learning.  In this first example we will use the sklearn library from python to carry out linear regression on the chosen subset of data i.e. molecular fingerprint and glass transition (Tg).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789cb5a-2716-4265-9720-327d59eb6f2e",
   "metadata": {},
   "source": [
    "## Machine Learning for Polymer Chemists: Linear Regression Analysis\n",
    "In the field of polymer chemistry, predicting properties such as the glass transition temperature of polymers based on their composition and processing conditions can significantly enhance material design and application. Machine learning, particularly linear regression, offers a powerful tool for such predictions. This section introduces you to applying linear regression to polymer datasets using Python's scikit-learn library.\n",
    "\n",
    "### Selecting Features and Target Variable\n",
    "    <br>`cols = [c for c in meta_df.columns if 'col' in c]`\n",
    "    <br>`X = new_df[cols]`\n",
    "    <br>`y = new_df['Glass transition temperature_value_median']`\n",
    "* `cols` identifies the features (independent variables) to be used in the model. We're selecting all columns from `meta_df` that contain the substring 'col', indicating they are relevant for our analysis.\n",
    "* X represents the matrix of features, and y is the target variable, here specifically the `Glass transition temperature_value_median` column from `new_df`, indicating the property we aim to predict.\n",
    "\n",
    "### Splitting the Dataset \n",
    "`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)`\n",
    "\n",
    "* This command splits the dataset into training and testing sets, with **30% of the data reserved for testing**. The `random_state` parameter ensures that the split is reproducible; different runs will produce the same split.\n",
    "\n",
    "### Training the Linear Regression Model\n",
    "<br>`model = LinearRegression()`\n",
    "<br>`model.fit(X_train, y_train)`\n",
    "\n",
    "`LinearRegression()` initializes the linear regression model.\n",
    "`model.fit(X_train, y_train)` trains the model on the training data, learning how the features relate to the target variable.\n",
    "\n",
    "### Making Predictions and Evaluating the Model\n",
    "<br>`y_pred = model.predict(X_test)`\n",
    "<br>`mse = mean_squared_error(y_test, y_pred)`\n",
    "<br>`print(f'Mean Squared Error: {mse}')`\n",
    "\n",
    "`model.predict(X_test)` uses the trained model to predict the glass transition temperatures for the test set.\n",
    "The model's performance is evaluated using the mean squared error (MSE) between the predicted and actual values. Lower MSE values indicate better model performance.\n",
    "\n",
    "### Interpreting the Model\n",
    "<br>`coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})`\n",
    "<br>`print(coefficients)`\n",
    "\n",
    "The coefficients of the linear regression model provide insights into the relationship between each feature and the target variable. Positive coefficients indicate a direct relationship, while negative coefficients indicate an inverse relationship. This information is crucial for understanding how different factors affect the glass transition temperature of polymers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdbabb20-dbcb-479a-876a-0b6cd4c531ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2588.400975051445\n",
      "       Feature  Coefficient\n",
      "0        col_0   -55.557757\n",
      "1        col_1    -1.966359\n",
      "2        col_2     5.969267\n",
      "3        col_3     8.019750\n",
      "4        col_4    -5.696441\n",
      "...        ...          ...\n",
      "1019  col_1019    21.319374\n",
      "1020  col_1020     4.141899\n",
      "1021  col_1021    16.478835\n",
      "1022  col_1022    -3.242184\n",
      "1023  col_1023    -3.075929\n",
      "\n",
      "[1024 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "cols = [c for c in meta_df.columns if 'col' in c]\n",
    "X = new_df[cols]\n",
    "y = new_df['Glass transition temperature_value_median']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Explore the coefficients of the linear regression model\n",
    "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f45559-7ad3-4977-9389-dc168c7df79e",
   "metadata": {},
   "source": [
    "## Understanding Mean Absolute Error (MAE) in Polymer Chemistry Modeling\n",
    "\n",
    "In the realm of polymer chemistry, accurately predicting material properties such as glass transition temperature, molecular weight, or tensile strength is pivotal for designing polymers with desired characteristics. Machine learning models, particularly regression models, are powerful tools for such predictions. Evaluating these models' performance is crucial to ensure their predictions are reliable and accurate. One common metric for evaluating regression models is the Mean Absolute Error (MAE). This section will guide you through understanding and applying MAE in the context of polymer chemistry modeling.\n",
    "\n",
    "The Concept of Mean Absolute Error\n",
    "\n",
    "Mean Absolute Error (MAE) is a metric used to quantify the accuracy of a model in regression tasks. It measures the average magnitude of the errors between predicted and actual values, without considering their direction. \n",
    "\n",
    "The formula for MAE is:\n",
    "\n",
    "$$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n",
    "\n",
    "Where:\n",
    "* $n$ is the number of observations,\n",
    "* $y_i$ is the actual value of the $i$th observation,\n",
    "* $\\hat{y}_i$ is the predicted value for the $i$th observation,\n",
    "* $|y_i - \\hat{y}_i|$ is the absolute error for each prediction.\n",
    "\n",
    "Applying MAE in Polymer Chemistry\n",
    "\n",
    "When applying machine learning to predict polymer properties, MAE can provide a straightforward indication of your model's average error magnitude in units of the property being predicted (e.g., °C for glass transition temperature).\n",
    "\n",
    "In this code below:\n",
    "\n",
    "`mean_absolute_error(y_test, y_pred)` computes the MAE between the actual (`y_test`) and predicted (`y_pred`) values. These values represent the actual and predicted polymer properties, respectively.\n",
    "`print(f'Mean Absolute Error: {mae:.3f}')` prints the MAE, formatted to three decimal places. This precision is often sufficient to assess the model's performance meaningfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94b42c6c-4c82-4d07-bbcd-90fdb20d8bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 37.645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Evaluate the model using Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad02202-ca32-4a36-8d79-211f20e30f4f",
   "metadata": {},
   "source": [
    "### Significance of MAE in Modeling\n",
    "\n",
    "* Interpretability: MAE is expressed in the same units as the target variable, making it intuitively easy to understand. For instance, an MAE of 2°C in predicting the glass transition temperature means that, on average, the model's predictions are 2°C off from the actual values.\n",
    "* Robustness: MAE is less sensitive to outliers than Mean Squared Error (MSE), making it a robust performance metric in applications where outliers are present but should not heavily influence model evaluation.\n",
    "\n",
    "#### Limitations and Considerations\n",
    "\n",
    "* Scale Dependency: MAE's interpretability can be a double-edged sword; its value is scale-dependent, making it less suitable for comparing model performance across datasets with different scales or units.\n",
    "* No Direction Information: MAE does not distinguish between underpredictions and overpredictions. In some polymer chemistry applications, the direction of the error might be crucial for specific engineering or design considerations.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "Mean Absolute Error is a valuable metric for evaluating regression models in polymer chemistry, offering a clear and interpretable measure of average prediction error. By integrating MAE into the model evaluation process, polymer chemists can quantitatively assess and improve their predictive models, ensuring they make accurate predictions that are vital for material design and application. However, it's essential to consider MAE in conjunction with other metrics and domain-specific knowledge to gain a comprehensive understanding of model performance.\n",
    "\n",
    "### This model's performance in terms of MAE\n",
    "\n",
    "The Mean Absolute Error (MAE) of 37.645 indicates that, on average, the predictions made by our model are 37.645 units away from the actual values. This metric provides a straightforward measure of the average magnitude of errors in your predictions, without considering their direction.\n",
    "\n",
    "In the context of our specific application (such as predicting a property of polymers), this value helps assess how accurately our model can predict new data. The units of MAE depend on the target variable we are predicting. For example, predicting the glass transition temperature of polymers in degrees Celsius, an MAE of 37.645 means that, on average, the model's predictions are about 37.645°C off from the actual glass transition temperatures.\n",
    "\n",
    "To improve the model, we can consider exploring more features, using a different model architecture, tuning hyperparameters, or increasing the dataset size, among other strategies. **The goal would be to lower the MAE, indicating better prediction accuracy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e6523-3fc6-4814-af04-c855e1becb82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The R-squared $(R^2)$ metric\n",
    "\n",
    "The R-squared or coefficient of determination is a statistical measure representing the proportion of variance for the dependent variable that is explained by the independent variables in the regression model and is calculated as outlined below:\n",
    "\n",
    "$$R^2=1-\\frac{SS_{res}}{SS_{tot}}$$\n",
    "\n",
    "where:\n",
    "* $SS_{res}$ is the sum of squares of residuals,\n",
    "* $SS_{tot}$ is the total sum of squares.\n",
    "\n",
    "It provides a measure of the goodness of fit of the model and typically ranges from 0 to 1 where:\n",
    "\n",
    "An $R^2$ of 0 indicates that the model explains none of the variability of the response data around its mean.\n",
    "An $R^2$ of 1 indicates that the model explains all the variability of the response data around its mean.\n",
    "\n",
    "In the code below: \n",
    "* `r2_score(y_test, y_pred)` calculates the $R^2$ score based on the actual values (`y_test`) and the predicted values (`y_pred`) from your model.\n",
    "* `print(f'R-squared: {r2:.3f}')` outputs the $R^2$ score, formatted to three decimal places, which can help in assessing the model's accuracy in a more digestible format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6879656d-136d-4f3d-94de-4fdcf47fcc30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.789\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R-squared: {r2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4aa80b-e146-4395-9104-960a7cb80a2f",
   "metadata": {},
   "source": [
    "### Evaluating $R^2$\n",
    "\n",
    "* **High $R^2$**: A high $R^2$ value (close to 1) suggests that the model has a good level of predictionn accuracy, capturing a significant portion of the observed variablity in the target variable.\n",
    "* **Low $R^2$**: A low $R^2$ value indicates that the model fails to accurately model the target variable and cannot account for a large portion of the variance in the data.\n",
    "* **Negative $R^2$**: Although rare in practice when using models like linear regression with the same dataset for training and testing, a negative $R^2$ can occur, especially with non-linear models or models evaluated on a very different dataset from the one they were trained on. It suggests that the model is worse than a simple horizontal line fitted to the data points. \n",
    "\n",
    "### Considerations\n",
    "* **Domain-Specific Benchmarks**: What constitutes a \"good\" $R^22$ score can vary widely between different fields and applications. It's important to compare our model's $R^2$ score against domain-specific benchmarks or expectations.\n",
    "* **Model Complexity**: Adding more variables to a model can artificially inflate the $R^2$, but it does not necessarily mean thge model has improved in a meaningful way. Adjusted $R^2$ can be used to account for the number of predictors in the model, providing a more accurate measure in the context of multiple regression. \n",
    "* **Model Purpose**: Consider the purpose of the model. If the goal is prediction, predictive accuracy on unseen data (e.e., using cross-validation techniques) might be more important than a high $R^2$ score.\n",
    "\n",
    "### Conclusion\n",
    "The $R^2$ score is a useful statistic for assessing the performance of a regression model, indicating how well the independent variables explain the variability of the dependent variable. However, it should be interpredted in context and alongside other performance metrics and domain-specific knowledge to fully evaluate a model's effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea6339-6e04-4dfa-8105-ab959539d783",
   "metadata": {},
   "source": [
    "## Understanding the Explained Variance Score in Polymer Chemistry Modeling\n",
    "Explained Variance Score is another metric used to evaluate the performance of regression models, such as those predicting properties of polymers. This metric provides insight into how much of the variance in the dependent variable (e.g., a polymer's glass transition temperature) your model can explain. It's particularly useful in assessing the accuracy of predictions and the model's ability to capture the underlying variability in the data. Here’s a deeper dive into the Explained Variance Score and its application in polymer chemistry modeling.\n",
    "\n",
    "### The Concept of Explained Variance Score\n",
    "The Explained Variance Score is defined as:\n",
    "$$ \\text{Explained Variance Score} = 1 - \\frac{\\text{Variance}(y_{true}-y_{pred})}{\\text{Variance}(y_{true})} $$\n",
    "\n",
    "where:\n",
    "* $y_{true}$ are the actual values,\n",
    "* $y_{pred}$ are the model's predicted values.\n",
    "\n",
    "A score of 1 indicates perfect prediction, while a score closer to 0 suggests the model fails to accurately capture the variance of the target variable. It is similar to the $R^2$ but differs slightly in its calculation.  Unlike $R^2$ which is rarely negative the Explained Variance Score may be negative indicating the model is worse than predicting the mean. \n",
    "\n",
    "In the code below: \n",
    "* `explained_variance_score(y_test, y_pred)` computes the Explained Variance Score between the actual (`y_test`) and predicted (`y_pred`) values, where these values represent the actual and predicted properties of polymers, respectively.\n",
    "* `print(f'Explained Variance Score: {variance_score:.3f}'`) prints the score, formatted to three decimal places, offering a clear and concise evaluation of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fef432c5-295d-4d72-91d5-b17d9efbf9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Score: 0.790\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "variance_score = explained_variance_score(y_test, y_pred)\n",
    "print(f'Explained Variance Score: {variance_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60acaf75-6743-40d2-b630-2f69d391b1f7",
   "metadata": {},
   "source": [
    "### Significance in Modeling\n",
    "\n",
    "* **Model Accuracy**: A high Explained Variance Score indicates that the model accurately predicts the variance in the polymer properties, showing that the model has captured the essential patterns in the data.\n",
    "* **Comparative Analysis**: This score can be used alongside other metrics like R-squared or Mean Absolute Error to provide a comprehensive picture of the model's performance.\n",
    "* **Optimization**: By assessing how well the model explains the variance of the target variable, researchers can identify areas for improvement in feature selection, model complexity, or data preprocessing.\n",
    "\n",
    "### Limitations and Considerations\n",
    "\n",
    "* **Sensitivity to Scale**: Like other regression metrics, the Explained Variance Score can be sensitive to the scale of the data, making it important to standardize or normalize data for meaningful comparisons.\n",
    "* **Not a Standalone Metric**: Relying solely on the Explained Variance Score might overlook aspects such as bias or the model's ability to handle outliers. Combining it with other evaluation metrics provides a more balanced view of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d130f4-6aca-4648-bfb6-c8654b01568e",
   "metadata": {},
   "source": [
    "## Key Differences between $R^2$ and Explained Variance Score:\n",
    "\n",
    "* **Sensitivity to Variance**: The main difference arises in how each metric handles the variance of the residuals. Explained Variance Score focuses on the variance of the errors (predicted values minus actual values), while R-Squared focuses on the proportion of total variance explained by the model.\n",
    "* **Interpretation in Presence of High Variance**: Under certain conditions, especially when the variance of the errors is high, the two metrics can diverge. The Explained Variance Score can become negative if the model is worse than simply predicting the mean of the target, whereas R-Squared is constrained between 0 and 1.\n",
    "* **Adjustment for Mean**: The calculation of R-Squared inherently adjusts for the mean of the target variable, making it slightly more robust in certain scenarios where the mean of the predictions does not align with the mean of the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b37683-2082-46af-a31b-8614ddeef592",
   "metadata": {},
   "source": [
    "## Median Absolute Error in Machine Learning for Polymer Chemists\n",
    "\n",
    "In the advancing field of polymer chemistry, the development and optimization of polymer materials benefit significantly from predictive modeling. Machine learning (ML) models can predict various polymer properties, such as mechanical strength, thermal stability, and glass transition temperature, based on molecular structures or processing conditions. Evaluating the accuracy and reliability of these models is crucial to ensuring their usefulness in practical applications. One such metric for model evaluation is the Median Absolute Error (MedAE). This section of the tutorial will introduce polymer chemists to the Median Absolute Error, its significance, and how to compute it using Python's scikit-learn library.\n",
    "\n",
    "### Understanding Median Absolute Error\n",
    "\n",
    "The Median Absolute Error is a robust metric used to measure the accuracy of regression models. It calculates the median of the absolute differences between the predicted values and the actual values. The formula can be represented as:\n",
    "\n",
    "$$MedAE = median(|y_i - \\hat{y}_i|)$$\n",
    "\n",
    "where:\n",
    "* $y_i$ are the actual values of the target variable,\n",
    "* $\\hat{y}_i$ are the predicted values by the model.\n",
    "\n",
    "### Computing MedAR in Python:\n",
    "In the code below:\n",
    "* `median_absolute_error(y_test, y_pred)` computes the MedAE between the actual (`y_test`) and predicted (`y_pred`) values. These values represent the actual and predicted polymer properties, respectively.\n",
    "* `print(f'Median Absolute Error: {medae:.3f}')` displays the MedAE, formatted to three decimal places, providing a concise measure of the model's prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00797cdc-b433-4e05-9221-ea7e212798e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Absolute Error: 27.782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "print(f'Median Absolute Error: {medae:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ab185b-6761-4d1f-abd3-fcfa5191caaf",
   "metadata": {},
   "source": [
    "### Significance of MedAE in Polymer Chemistry Modeling\n",
    "\n",
    "**Robustness**: MedAE is less sensitive to outliers than other metrics such as the mean absolute error. This makes it particularly useful in polymer chemistry, where experimental data can sometimes include outliers due to measurement errors or anomalous samples.\n",
    "Interpretability: MedAE provides a direct measure of the typical prediction error in the same units as the target variable. For example, a MedAE of 2°C in predicting glass transition temperatures means that half of the predictions are within 2°C of the actual values.\n",
    "\n",
    "### Limitations and Considerations\n",
    "\n",
    "**Sensitivity to Scale**: Like other absolute error metrics, MedAE's interpretability is scale-dependent. When comparing models across different datasets or properties, consider normalizing or standardizing the data.\n",
    "Not a Standalone Metric: While MedAE is a valuable tool for assessing model performance, it does not provide information about the error distribution or model bias. It's best used alongside other metrics, such as R-squared or Mean Absolute Error, for a comprehensive evaluation.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The Median Absolute Error is an essential metric for evaluating the accuracy of machine learning models in polymer chemistry. Its robustness to outliers and straightforward interpretability make it particularly suited for experimental datasets, which may include anomalies or vary widely in scale. By incorporating MedAE into the model evaluation process, polymer chemists can gain valuable insights into the typical accuracy of their predictive models, guiding improvements in model development and ensuring the reliability of predictions for polymer properties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
